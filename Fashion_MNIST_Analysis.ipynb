{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "416d425d2f360047c1a7f8098c9866d88c82a4f0"
   },
   "source": [
    "# Fashion_MNIST  Data Analysis Using CNN\n",
    "\n",
    " ##   About Data Set:\n",
    "*         Fasion MNIST data set is a new image classification data set developed by Researchers at [Zalando](http://www.zalando.com/). This new dataset contains images of various articles of clothing and accessories — such as shirts, bags, shoes, and other fashion items.\n",
    "*         It consists of 60,000 train examples and 10,000 test examples, each example is 28x28 grayscale image with a label from 10 classes.\n",
    "*         Here is an example how the MNIST _Fashion data looks like\n",
    "\n",
    "![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/03/Fashion-MNIST.png)  \n",
    "\n",
    "  ##   Following are the steps followed in the building the CNN model on Fasion_MNIST data set\n",
    "   *          Loading Dependencies.\n",
    "   *          Loading Data.\n",
    "   *          Spilit the Data into Pixels and Labels.\n",
    "   *          Pre-process the data.\n",
    "   *          Design the NN architecture\n",
    "   *          Compile the model.\n",
    "   *          Fit the Model with train and test sets.\n",
    "   *          Plot the Result.\n",
    "   *          Conclusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3907777fc4cbb91bd6ded4481519742faf648cc"
   },
   "source": [
    "### Loading Dependencies.\n",
    "   * Here We load all the Libraries required for the Loading, Pre-Processing of data and Building,Compiling Fitting of model \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Conv2D,Flatten,MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "#print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7bbd0be67f22fca941bf7d1f8939531a4bec10e1"
   },
   "source": [
    "### Loading the data\n",
    "*  Load data using Pandas into Data Frame objects .\n",
    "*  Convert into Numpy array type for Pre-processing ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/fashion-mnist_train.csv')\n",
    "df_test = pd.read_csv('../input/fashion-mnist_test.csv')\n",
    "train = np.array(df_train,dtype = 'float32')\n",
    "test  = np.array(df_test,dtype = 'float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ca4f5651750bfac36af01e1c1d2ae5c0b544959"
   },
   "source": [
    "### Pre-Processing.\n",
    "1.     Split Train and Test data sets into Pixels and Labels.\n",
    "1.     Apply Normalization on the train and test Pixels.\n",
    "1.     Apply One-Hot Encoding to the train and test Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c85f89c870b663b7d03c4c0cbd8f5c408b0ac93f"
   },
   "outputs": [],
   "source": [
    "# Splitting the dats sets.\n",
    "X_train = train[:,1:].astype('float32')\n",
    "y_train = train[:,0].astype('float32')\n",
    "X_test  = test[:,1:].astype('float32')\n",
    "y_test  = test[:,0].astype('float32')\n",
    "\n",
    "# Normalization.\n",
    "X_train = X_train/255\n",
    "X_test  = X_test/255\n",
    "\n",
    "# One-Hot Encoding. \n",
    "n_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train,n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test,n_classes) \n",
    "\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(10000, 28, 28, 1).astype('float32')\n",
    "\n",
    "# Checking the Shape after Pre porcessing\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4bfa281195efdbf5d087a7cdcf79ca001b03ab2d"
   },
   "source": [
    "\n",
    " ### Desing the CNN Architecture\n",
    " **Steps**\n",
    "*     Defind the Sequential Model.\n",
    "*     Define Conv Layer with 32 filters, each filter size = (3x3)  with RELU activation and define the Shape of Input data.\n",
    "*     Define Conv Layer with 64 filters,each filter size= (3x3) with RELU activation ( We dont have to defins the input to this layer, output of Layer-1 is considered as input for Layer-2).\n",
    "*     Define Maxpooling with Pool size = (2x2).\n",
    "*     Define Dense Layer with 128 Neurins and activation as RELU.\n",
    "*     Define Dense Layer with 10 Neurons,This is the output layer with SOFTMAX activation function and it has 10 output units to detect 10 different types of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0dc1995acb7564a15905377a0f7d9ae798fa1e69"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "900a4c7dc38df9666e5f7ec6702ed7b3c41aea9e"
   },
   "source": [
    "### Compile the Model\n",
    "**Patameters**\n",
    "*  Loss.\n",
    "*  Optimizer.\n",
    "*  Metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ccd85ad059240f9f8b3f4d0598d25756a92f15d"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d207764974165aa19b23a3f88d54ed01b28b0512"
   },
   "source": [
    "### Fit the Model\n",
    "**Patameters**\n",
    "*  Batch_size.\n",
    "*  Epochs.\n",
    "*  Verbose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6bd4a7aab6123615742f92775d05b356e74a2ac7"
   },
   "outputs": [],
   "source": [
    "result = model.fit(X_train, y_train, batch_size=128, epochs=15, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a20f91510c7c91c59f5ccaf58bbbf6a6d6a83135"
   },
   "source": [
    "### Plot the Results\n",
    "1.     Train Set Accracy vs Test Accuracy.\n",
    "1.     Train Set Loss vs Test Set Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cfdb998f927d40b1c957905de246fbecfcc50041"
   },
   "outputs": [],
   "source": [
    "# Train Set Accracy vs Test Accuracy.\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(['train','test'],loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "# Train Set Loss vs Test Set Accuracy.\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Model Loss')\n",
    "plt.legend(['train','test'],loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b0f2b4f90c76ebe17aaaab5ed4c2aed90448ed0e"
   },
   "source": [
    "### Conclusions.\n",
    "#### After 7 Epochs :\n",
    "*  Train Set Accuracy = 92.27 % , Test Set  Accuracy = 92.70 %\n",
    "*  Train Set Loss= 0.2120  , Test Set Accuracy = 0.2032.\n",
    "*  After 7 epochs, Training set accuracy continues to increases and Test set accuracy starts to decreases where we can see the Overfitting of Model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05ca20c9ddb035e0d830f9cf745dec0a8e18d162"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
